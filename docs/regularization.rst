.. _regularization:

==============
Regularization
==============

.. contents:: :local:

Techniques for combating overfitting and improving training.

Data Augmentation
=================

Be the first to `contribute! <https://github.com/bfortuner/ml-cheatsheet>`__

Dropout
=======

Dropout became common in deep learning technics. It's principle is to randomly remove some connections between two layers when training your model in an effort to avoid an overfitting.
As a matrix, Dropout can be implemented as:
.. code::


Early Stopping
==============

Be the first to `contribute! <https://github.com/bfortuner/ml-cheatsheet>`__

Ensembling
==========

Be the first to `contribute! <https://github.com/bfortuner/ml-cheatsheet>`__

Injecting Noise
===============

Be the first to `contribute! <https://github.com/bfortuner/ml-cheatsheet>`__

L1 Regularization
=================

Be the first to `contribute! <https://github.com/bfortuner/ml-cheatsheet>`__

L2 Regularization
=================

Be the first to `contribute! <https://github.com/bfortuner/ml-cheatsheet>`__



.. rubric:: References

.. [1] http://www.deeplearningbook.org/contents/regularization.html
